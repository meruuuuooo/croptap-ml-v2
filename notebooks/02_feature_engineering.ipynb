{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering\n",
        "\n",
        "This notebook creates the training dataset by merging three real datasets:\n",
        "1. **Historical Crop Performance**: Actual yields per crop-province-year\n",
        "2. **Soil Test Data**: Real farmer soil conditions (NPK, pH) aggregated by province\n",
        "3. **Climate Data**: 5-year averages (2020-2024) for temperature, rainfall, humidity\n",
        "\n",
        "Then:\n",
        "- Extracts 9 features for each crop-province-soil combination\n",
        "- Creates target suitability scores from actual historical yields\n",
        "- Uses REAL data instead of simulated values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n",
            "Loaded 104 crop climate requirements\n",
            "Loaded 104 crop requirements\n",
            "Loaded 104 NPK requirements\n",
            "Loaded 93369 historical performance records\n",
            "Loading climate data (this may take a moment)...\n",
            "Loaded 215556 climate records\n",
            "Creating unified crop database...\n",
            "Unified database created with 104 crops\n",
            "Data loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add app to path to import modules\n",
        "project_root = Path(\"../\").resolve()\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "from app.services.data_loader import DataLoader\n",
        "from app.services.feature_extractor import FeatureExtractor\n",
        "from app.utils.data_processor import normalize_npk_level, parse_ph_range, parse_soil_types\n",
        "\n",
        "# Initialize with explicit data directory path\n",
        "data_dir = project_root / \"raw_datasets\"\n",
        "data_loader = DataLoader(data_dir=str(data_dir))\n",
        "data_loader.load_all_data()\n",
        "feature_extractor = FeatureExtractor()\n",
        "\n",
        "print(\"Data loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid yield records: 93369\n"
          ]
        }
      ],
      "source": [
        "# Load historical performance and calculate yields\n",
        "historical_perf = pd.read_csv(\"../raw_datasets/historical_crop_performance.csv\")\n",
        "historical_perf['yield_per_ha'] = (\n",
        "    historical_perf['Volume_Production'] / historical_perf['Area_Planted_Harvested']\n",
        ")\n",
        "\n",
        "# Clean data\n",
        "historical_perf_clean = historical_perf[\n",
        "    (historical_perf['yield_per_ha'].notna()) & \n",
        "    (historical_perf['yield_per_ha'] != float('inf')) &\n",
        "    (historical_perf['yield_per_ha'] > 0)\n",
        "].copy()\n",
        "\n",
        "print(f\"Valid yield records: {len(historical_perf_clean)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading soil test data...\n",
            "Loaded 22242 soil test records\n",
            "Aggregated soil data for 62 provinces\n",
            "\n",
            "Merging historical data with soil data...\n",
            "Total merged records: 65898\n",
            "Records with soil data: 65898\n",
            "Unique crop-province combinations with soil data: 3935\n"
          ]
        }
      ],
      "source": [
        "# Load and aggregate soil test data\n",
        "print(\"Loading soil test data...\")\n",
        "soil_test_df = pd.read_csv(\"../raw_datasets/soil_test_data.csv\")\n",
        "print(f\"Loaded {len(soil_test_df)} soil test records\")\n",
        "\n",
        "# Normalize province names for matching\n",
        "soil_test_df['province_normalized'] = soil_test_df['province'].str.strip().str.title()\n",
        "\n",
        "# Aggregate soil data by province (get most common values)\n",
        "def get_mode_or_default(series, default='Medium'):\n",
        "    \"\"\"Get mode value or return default if empty.\"\"\"\n",
        "    mode_values = series.mode()\n",
        "    return mode_values[0] if len(mode_values) > 0 else default\n",
        "\n",
        "province_soil_agg = soil_test_df.groupby('province_normalized').agg({\n",
        "    'nitrogen': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'phosphorus': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'potassium': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'ph_min': 'mean',\n",
        "    'ph_max': 'mean'\n",
        "}).reset_index()\n",
        "province_soil_agg.columns = ['province', 'nitrogen', 'phosphorus', 'potassium', 'ph_min', 'ph_max']\n",
        "\n",
        "print(f\"Aggregated soil data for {len(province_soil_agg)} provinces\")\n",
        "\n",
        "# Normalize province names in historical data for merging\n",
        "historical_perf_clean['Province_normalized'] = historical_perf_clean['Province'].str.strip().str.title()\n",
        "\n",
        "# Merge historical performance with soil data\n",
        "print(\"\\nMerging historical data with soil data...\")\n",
        "merged_data = historical_perf_clean.merge(\n",
        "    province_soil_agg,\n",
        "    left_on='Province_normalized',\n",
        "    right_on='province',\n",
        "    how='inner'  # Only keep records with soil data\n",
        ")\n",
        "\n",
        "print(f\"Total merged records: {len(merged_data)}\")\n",
        "print(f\"Records with soil data: {merged_data['nitrogen'].notna().sum()}\")\n",
        "print(f\"Unique crop-province combinations with soil data: {merged_data[['Crop', 'Province']].drop_duplicates().shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 5000 records with real soil, climate, and yield data...\n",
            "Processed 500 records...\n",
            "Processed 1000 records...\n",
            "Processed 1500 records...\n",
            "Processed 2000 records...\n",
            "Processed 2500 records...\n",
            "Processed 3000 records...\n",
            "Processed 3500 records...\n",
            "Processed 4000 records...\n",
            "Processed 4500 records...\n",
            "\n",
            "Total training records created: 4884\n",
            "Records with valid data: 4884\n"
          ]
        }
      ],
      "source": [
        "# Create training dataset using merged data\n",
        "training_data = []\n",
        "\n",
        "# Sample a subset for faster processing (adjust as needed)\n",
        "sample_size = min(5000, len(merged_data))\n",
        "merged_sample = merged_data.sample(n=sample_size, random_state=42)\n",
        "\n",
        "print(f\"Processing {len(merged_sample)} records with real soil, climate, and yield data...\")\n",
        "\n",
        "for idx, row in merged_sample.iterrows():\n",
        "    crop_name = row['Crop']\n",
        "    province = row['Province']\n",
        "    yield_per_ha = row['yield_per_ha']\n",
        "    \n",
        "    try:\n",
        "        # Get crop data\n",
        "        crop_data = data_loader.get_crop_by_name(crop_name)\n",
        "        if crop_data is None:\n",
        "            continue\n",
        "        \n",
        "        # Get climate averages for province\n",
        "        try:\n",
        "            climate = data_loader.get_climate_averages(province, None)\n",
        "            if not all([climate['temperature'], climate['rainfall'], climate['humidity']]):\n",
        "                continue\n",
        "        except Exception as e:\n",
        "            continue\n",
        "        \n",
        "        # Use REAL soil data from merged dataset\n",
        "        farmer_nitrogen = str(row['nitrogen'])\n",
        "        farmer_phosphorus = str(row['phosphorus'])\n",
        "        farmer_potassium = str(row['potassium'])\n",
        "        farmer_ph_min = float(row['ph_min'])\n",
        "        farmer_ph_max = float(row['ph_max'])\n",
        "        \n",
        "        # Soil type - use common type (most common in Philippines)\n",
        "        # Could be improved by sampling from crop's acceptable types\n",
        "        farmer_soil_type = \"Loam\"\n",
        "        \n",
        "        # Get historical yield data for feature extraction (for regional success rate)\n",
        "        hist_data = data_loader.get_historical_yield(crop_name, province)\n",
        "        \n",
        "        # Extract features using REAL data\n",
        "        features = feature_extractor.extract_features(\n",
        "            crop_data=crop_data,\n",
        "            farmer_nitrogen=farmer_nitrogen,\n",
        "            farmer_phosphorus=farmer_phosphorus,\n",
        "            farmer_potassium=farmer_potassium,\n",
        "            farmer_ph_min=farmer_ph_min,\n",
        "            farmer_ph_max=farmer_ph_max,\n",
        "            farmer_soil_type=farmer_soil_type,\n",
        "            avg_temperature=climate['temperature'],\n",
        "            avg_rainfall=climate['rainfall'],\n",
        "            avg_humidity=climate['humidity'],\n",
        "            historical_yield_data=hist_data,  # For regional success features\n",
        "            current_month=6  # June (can be varied)\n",
        "        )\n",
        "        \n",
        "        # Calculate target suitability score from ACTUAL yield\n",
        "        # Normalize yield to 0-100 score (assume max expected yield is 20 tons/ha)\n",
        "        suitability_score = min(100.0, max(0.0, (yield_per_ha / 20.0) * 80.0 + 20.0))\n",
        "        \n",
        "        # Add to training data\n",
        "        training_row = features.copy()\n",
        "        training_row['suitability_score'] = suitability_score\n",
        "        training_row['crop_name'] = crop_name\n",
        "        training_row['province'] = province\n",
        "        training_row['category'] = crop_data.get('Category', 'Unknown')\n",
        "        training_row['actual_yield'] = yield_per_ha  # Keep actual yield for reference\n",
        "        \n",
        "        training_data.append(training_row)\n",
        "        \n",
        "    except Exception as e:\n",
        "        if len(training_data) % 1000 == 0:  # Only print errors occasionally\n",
        "            print(f\"Error processing {crop_name} in {province}: {e}\")\n",
        "        continue\n",
        "    \n",
        "    if len(training_data) % 500 == 0:\n",
        "        print(f\"Processed {len(training_data)} records...\")\n",
        "\n",
        "print(f\"\\nTotal training records created: {len(training_data)}\")\n",
        "print(f\"Records with valid data: {len([r for r in training_data if r.get('suitability_score', 0) > 0])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset shape: (4884, 14)\n",
            "\n",
            "Columns: ['npk_match', 'ph_proximity', 'temp_suitability', 'rainfall_suitability', 'humidity_suitability', 'soil_match', 'historical_yield', 'season_alignment', 'regional_success', 'suitability_score', 'crop_name', 'province', 'category', 'actual_yield']\n",
            "\n",
            "First few rows:\n",
            "   npk_match  ph_proximity  temp_suitability  rainfall_suitability  \\\n",
            "0   0.000000      0.801245          0.956212              0.510209   \n",
            "1   0.000000      0.547619          0.780627              0.000000   \n",
            "2   0.666667      0.819444          0.607525              0.124888   \n",
            "3   0.666667      0.802083          0.913970              0.000000   \n",
            "4   0.666667      0.895717          0.729678              0.000000   \n",
            "\n",
            "   humidity_suitability  soil_match  historical_yield  season_alignment  \\\n",
            "0              0.941970         0.3          1.000000               1.0   \n",
            "1              0.821305         1.0          0.416671               1.0   \n",
            "2              0.782908         1.0          1.000000               1.0   \n",
            "3              0.581100         1.0          0.630325               1.0   \n",
            "4              0.767406         0.3          1.000000               1.0   \n",
            "\n",
            "   regional_success  suitability_score                    crop_name  \\\n",
            "0               1.0          20.646667  Calamansi (Philippine lime)   \n",
            "1               1.0          39.220457              Pili (Pili nut)   \n",
            "2               1.0         100.000000      Luyang dilaw (Turmeric)   \n",
            "3               1.0          26.782400                 Kidney beans   \n",
            "4               1.0          88.013333            Talong (Eggplant)   \n",
            "\n",
            "              province          category  actual_yield  \n",
            "0  Zamboanga del Norte       Fruit Trees      0.161667  \n",
            "1                Albay       Fruit Trees      4.805114  \n",
            "2              Biliran        Root Crops     84.780000  \n",
            "3        Nueva Vizcaya        Vegetables      1.695600  \n",
            "4        Eastern Samar  Fruit Vegetables     17.003333  \n",
            "\n",
            "Target variable (suitability_score) statistics:\n",
            "count    4884.000000\n",
            "mean       57.991158\n",
            "std        31.910568\n",
            "min        20.001253\n",
            "25%        28.053527\n",
            "50%        46.697454\n",
            "75%       100.000000\n",
            "max       100.000000\n",
            "Name: suitability_score, dtype: float64\n",
            "\n",
            "Training dataset saved to models/training_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "# Convert to DataFrame\n",
        "train_df = pd.DataFrame(training_data)\n",
        "\n",
        "print(\"Training dataset shape:\", train_df.shape)\n",
        "print(\"\\nColumns:\", train_df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nTarget variable (suitability_score) statistics:\")\n",
        "print(train_df['suitability_score'].describe())\n",
        "\n",
        "# Save training dataset\n",
        "train_df.to_csv(\"../models/training_dataset.csv\", index=False)\n",
        "print(\"\\nTraining dataset saved to models/training_dataset.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
