{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering\n",
        "\n",
        "This notebook creates the training dataset by merging three real datasets:\n",
        "1. **Historical Crop Performance**: Actual yields per crop-province-year\n",
        "2. **Soil Test Data**: Real farmer soil conditions (NPK, pH) aggregated by province\n",
        "3. **Climate Data**: 5-year averages (2020-2024) for temperature, rainfall, humidity\n",
        "\n",
        "Then:\n",
        "- Extracts 9 features for each crop-province-soil combination\n",
        "- Creates target suitability scores from actual historical yields\n",
        "- Uses REAL data instead of simulated values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n",
            "Loaded 104 crop climate requirements\n",
            "Loaded 104 crop requirements\n",
            "Loaded 104 NPK requirements\n",
            "Loaded 93369 historical performance records\n",
            "Loading climate data (this may take a moment)...\n",
            "Loaded 215556 climate records\n",
            "Creating unified crop database...\n",
            "Unified database created with 104 crops\n",
            "Data loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import random\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Add app to path to import modules\n",
        "project_root = Path(\"../\").resolve()\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "from app.services.data_loader import DataLoader\n",
        "from app.services.feature_extractor import FeatureExtractor\n",
        "from app.utils.data_processor import normalize_npk_level, parse_ph_range, parse_soil_types\n",
        "\n",
        "# Initialize with explicit data directory path\n",
        "data_dir = project_root / \"raw_datasets\"\n",
        "data_loader = DataLoader(data_dir=str(data_dir))\n",
        "data_loader.load_all_data()\n",
        "feature_extractor = FeatureExtractor()\n",
        "\n",
        "print(\"Data loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid yield records: 93369\n"
          ]
        }
      ],
      "source": [
        "# Load historical performance and calculate yields\n",
        "historical_perf = pd.read_csv(\"../raw_datasets/historical_crop_performance.csv\")\n",
        "historical_perf['yield_per_ha'] = (\n",
        "    historical_perf['Volume_Production'] / historical_perf['Area_Planted_Harvested']\n",
        ")\n",
        "\n",
        "# Clean data\n",
        "historical_perf_clean = historical_perf[\n",
        "    (historical_perf['yield_per_ha'].notna()) & \n",
        "    (historical_perf['yield_per_ha'] != float('inf')) &\n",
        "    (historical_perf['yield_per_ha'] > 0)\n",
        "].copy()\n",
        "\n",
        "print(f\"Valid yield records: {len(historical_perf_clean)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading soil test data...\n",
            "Loaded 22242 soil test records\n",
            "Aggregated soil data for 62 provinces\n",
            "\n",
            "Merging historical data with soil data...\n",
            "Total merged records: 65898\n",
            "Records with soil data: 65898\n",
            "Unique crop-province combinations with soil data: 3935\n"
          ]
        }
      ],
      "source": [
        "# Load and aggregate soil test data\n",
        "print(\"Loading soil test data...\")\n",
        "soil_test_df = pd.read_csv(\"../raw_datasets/soil_test_data.csv\")\n",
        "print(f\"Loaded {len(soil_test_df)} soil test records\")\n",
        "\n",
        "# Normalize province names for matching\n",
        "soil_test_df['province_normalized'] = soil_test_df['province'].str.strip().str.title()\n",
        "\n",
        "# Aggregate soil data by province (get most common values)\n",
        "def get_mode_or_default(series, default='Medium'):\n",
        "    \"\"\"Get mode value or return default if empty.\"\"\"\n",
        "    mode_values = series.mode()\n",
        "    return mode_values[0] if len(mode_values) > 0 else default\n",
        "\n",
        "province_soil_agg = soil_test_df.groupby('province_normalized').agg({\n",
        "    'nitrogen': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'phosphorus': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'potassium': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'ph_min': 'mean',\n",
        "    'ph_max': 'mean'\n",
        "}).reset_index()\n",
        "province_soil_agg.columns = ['province', 'nitrogen', 'phosphorus', 'potassium', 'ph_min', 'ph_max']\n",
        "\n",
        "print(f\"Aggregated soil data for {len(province_soil_agg)} provinces\")\n",
        "\n",
        "# Normalize province names in historical data for merging\n",
        "historical_perf_clean['Province_normalized'] = historical_perf_clean['Province'].str.strip().str.title()\n",
        "\n",
        "# Merge historical performance with soil data\n",
        "print(\"\\nMerging historical data with soil data...\")\n",
        "merged_data = historical_perf_clean.merge(\n",
        "    province_soil_agg,\n",
        "    left_on='Province_normalized',\n",
        "    right_on='province',\n",
        "    how='inner'  # Only keep records with soil data\n",
        ")\n",
        "\n",
        "print(f\"Total merged records: {len(merged_data)}\")\n",
        "print(f\"Records with soil data: {merged_data['nitrogen'].notna().sum()}\")\n",
        "print(f\"Unique crop-province combinations with soil data: {merged_data[['Crop', 'Province']].drop_duplicates().shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Crop</th>\n",
              "      <th>Province</th>\n",
              "      <th>Year</th>\n",
              "      <th>Volume_Production</th>\n",
              "      <th>Area_Planted_Harvested</th>\n",
              "      <th>yield_per_ha</th>\n",
              "      <th>Province_normalized</th>\n",
              "      <th>province</th>\n",
              "      <th>nitrogen</th>\n",
              "      <th>phosphorus</th>\n",
              "      <th>potassium</th>\n",
              "      <th>ph_min</th>\n",
              "      <th>ph_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alugbati (Malabar spinach)</td>\n",
              "      <td>Abra</td>\n",
              "      <td>2023</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.815217</td>\n",
              "      <td>Abra</td>\n",
              "      <td>Abra</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>6.026508</td>\n",
              "      <td>7.296770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alugbati (Malabar spinach)</td>\n",
              "      <td>Abra</td>\n",
              "      <td>2024</td>\n",
              "      <td>0.51</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>Abra</td>\n",
              "      <td>Abra</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>6.026508</td>\n",
              "      <td>7.296770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alugbati (Malabar spinach)</td>\n",
              "      <td>Agusan del Norte</td>\n",
              "      <td>2010</td>\n",
              "      <td>48.65</td>\n",
              "      <td>12.00</td>\n",
              "      <td>4.054167</td>\n",
              "      <td>Agusan Del Norte</td>\n",
              "      <td>Agusan Del Norte</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7.064912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alugbati (Malabar spinach)</td>\n",
              "      <td>Agusan del Norte</td>\n",
              "      <td>2011</td>\n",
              "      <td>45.85</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.585000</td>\n",
              "      <td>Agusan Del Norte</td>\n",
              "      <td>Agusan Del Norte</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7.064912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alugbati (Malabar spinach)</td>\n",
              "      <td>Agusan del Norte</td>\n",
              "      <td>2012</td>\n",
              "      <td>42.00</td>\n",
              "      <td>9.50</td>\n",
              "      <td>4.421053</td>\n",
              "      <td>Agusan Del Norte</td>\n",
              "      <td>Agusan Del Norte</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7.064912</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Crop          Province  Year  Volume_Production  \\\n",
              "0  Alugbati (Malabar spinach)              Abra  2023               0.75   \n",
              "1  Alugbati (Malabar spinach)              Abra  2024               0.51   \n",
              "2  Alugbati (Malabar spinach)  Agusan del Norte  2010              48.65   \n",
              "3  Alugbati (Malabar spinach)  Agusan del Norte  2011              45.85   \n",
              "4  Alugbati (Malabar spinach)  Agusan del Norte  2012              42.00   \n",
              "\n",
              "   Area_Planted_Harvested  yield_per_ha Province_normalized          province  \\\n",
              "0                    0.92      0.815217                Abra              Abra   \n",
              "1                    1.00      0.510000                Abra              Abra   \n",
              "2                   12.00      4.054167    Agusan Del Norte  Agusan Del Norte   \n",
              "3                   10.00      4.585000    Agusan Del Norte  Agusan Del Norte   \n",
              "4                    9.50      4.421053    Agusan Del Norte  Agusan Del Norte   \n",
              "\n",
              "  nitrogen phosphorus potassium    ph_min    ph_max  \n",
              "0      Low        Low       Low  6.026508  7.296770  \n",
              "1      Low        Low       Low  6.026508  7.296770  \n",
              "2     High        Low    Medium  5.833333  7.064912  \n",
              "3     High        Low    Medium  5.833333  7.064912  \n",
              "4     High        Low    Medium  5.833333  7.064912  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 65898 records...\n",
            "Processed 5000 records...\n",
            "Processed 10000 records...\n",
            "Processed 15000 records...\n",
            "Processed 20000 records...\n",
            "Processed 25000 records...\n",
            "Processed 30000 records...\n",
            "Processed 35000 records...\n",
            "Processed 40000 records...\n",
            "Processed 45000 records...\n",
            "Processed 50000 records...\n",
            "Processed 55000 records...\n",
            "Processed 60000 records...\n",
            "\n",
            "Total training records created: 64290\n"
          ]
        }
      ],
      "source": [
        "# Calculate the 95th percentile yield for each crop\n",
        "max_yield_per_crop = historical_perf_clean.groupby('Crop')['yield_per_ha'].quantile(0.95)\n",
        "\n",
        "# Create training dataset using the entire merged dataset\n",
        "training_data = []\n",
        "\n",
        "print(f\"Processing {len(merged_data)} records...\")\n",
        "\n",
        "for idx, row in merged_data.iterrows():\n",
        "    crop_name = row['Crop']\n",
        "    province = row['Province']\n",
        "    yield_per_ha = row['yield_per_ha']\n",
        "    \n",
        "    try:\n",
        "        crop_data = data_loader.get_crop_by_name(crop_name)\n",
        "        if crop_data is None:\n",
        "            continue\n",
        "        \n",
        "        climate = data_loader.get_climate_averages(province, None)\n",
        "        if not all([climate['temperature'], climate['rainfall'], climate['humidity']]):\n",
        "            continue\n",
        "        \n",
        "        # Use a realistic soil type\n",
        "        acceptable_soils = parse_soil_types(crop_data.get('Acceptable_Soil_Types', 'Loam'))\n",
        "        farmer_soil_type = random.choice(acceptable_soils) if acceptable_soils else 'Loam'\n",
        "\n",
        "        features = feature_extractor.extract_features(\n",
        "            crop_data=crop_data,\n",
        "            farmer_nitrogen=str(row['nitrogen']),\n",
        "            farmer_phosphorus=str(row['phosphorus']),\n",
        "            farmer_potassium=str(row['potassium']),\n",
        "            farmer_ph_min=float(row['ph_min']),\n",
        "            farmer_ph_max=float(row['ph_max']),\n",
        "            farmer_soil_type=farmer_soil_type,\n",
        "            avg_temperature=climate['temperature'],\n",
        "            avg_rainfall=climate['rainfall'],\n",
        "            avg_humidity=climate['humidity'],\n",
        "            historical_yield_data=data_loader.get_historical_yield(crop_name, province),\n",
        "            current_month=6\n",
        "        )\n",
        "        \n",
        "        # Dynamic suitability score\n",
        "        max_yield = max_yield_per_crop.get(crop_name, 20) # Default to 20 if crop not in series\n",
        "        suitability_score = min(100.0, max(0.0, (yield_per_ha / max_yield) * 80.0 + 20.0))\n",
        "        \n",
        "        training_row = features.copy()\n",
        "        training_row['suitability_score'] = suitability_score\n",
        "        training_row['crop_name'] = crop_name\n",
        "        training_row['province'] = province\n",
        "        training_row['category'] = crop_data.get('Category', 'Unknown')\n",
        "        training_row['actual_yield'] = yield_per_ha\n",
        "        \n",
        "        training_data.append(training_row)\n",
        "        \n",
        "    except Exception as e:\n",
        "        continue\n",
        "    \n",
        "    if len(training_data) % 5000 == 0:\n",
        "        print(f\"Processed {len(training_data)} records...\")\n",
        "\n",
        "print(f\"\\nTotal training records created: {len(training_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full dataset shape: (64290, 14)\n",
            "Training set shape: (51432, 14)\n",
            "Validation set shape: (12858, 14)\n",
            "\n",
            "Training and validation datasets saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Convert to DataFrame\n",
        "train_df = pd.DataFrame(training_data)\n",
        "print(\"Full dataset shape:\", train_df.shape)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_set, val_set = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: {train_set.shape}\")\n",
        "print(f\"Validation set shape: {val_set.shape}\")\n",
        "\n",
        "# Save the datasets\n",
        "output_dir = Path(\"../models\")\n",
        "train_set.to_csv(output_dir / \"training_dataset.csv\", index=False)\n",
        "val_set.to_csv(output_dir / \"validation_dataset.csv\", index=False)\n",
        "\n",
        "print(\"\\nTraining and validation datasets saved successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
