{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering\n",
        "\n",
        "This notebook creates the training dataset by merging three real datasets:\n",
        "1. **Historical Crop Performance**: Actual yields per crop-province-year\n",
        "2. **Soil Test Data**: Real farmer soil conditions (NPK, pH) aggregated by province\n",
        "3. **Climate Data**: 5-year averages (2020-2024) for temperature, rainfall, humidity\n",
        "\n",
        "Then:\n",
        "- Extracts 9 features for each crop-province-soil combination\n",
        "- Creates target suitability scores from actual historical yields\n",
        "- Uses REAL data instead of simulated values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import random\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Add app to path to import modules\n",
        "project_root = Path(\"../\").resolve()\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "from app.services.data_loader import DataLoader\n",
        "from app.services.feature_extractor import FeatureExtractor\n",
        "from app.utils.data_processor import normalize_npk_level, parse_ph_range, parse_soil_types\n",
        "\n",
        "# Initialize with explicit data directory path\n",
        "data_dir = project_root / \"raw_datasets\"\n",
        "data_loader = DataLoader(data_dir=str(data_dir))\n",
        "data_loader.load_all_data()\n",
        "feature_extractor = FeatureExtractor()\n",
        "\n",
        "print(\"Data loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load historical performance and calculate yields\n",
        "historical_perf = pd.read_csv(\"../raw_datasets/historical_crop_performance.csv\")\n",
        "historical_perf['yield_per_ha'] = (\n",
        "    historical_perf['Volume_Production'] / historical_perf['Area_Planted_Harvested']\n",
        ")\n",
        "\n",
        "# Clean data\n",
        "historical_perf_clean = historical_perf[\n",
        "    (historical_perf['yield_per_ha'].notna()) & \n",
        "    (historical_perf['yield_per_ha'] != float('inf')) &\n",
        "    (historical_perf['yield_per_ha'] > 0)\n",
        "].copy()\n",
        "\n",
        "print(f\"Valid yield records: {len(historical_perf_clean)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and aggregate soil test data\n",
        "print(\"Loading soil test data...\")\n",
        "soil_test_df = pd.read_csv(\"../raw_datasets/soil_test_data.csv\")\n",
        "print(f\"Loaded {len(soil_test_df)} soil test records\")\n",
        "\n",
        "# Normalize province names for matching\n",
        "soil_test_df['province_normalized'] = soil_test_df['province'].str.strip().str.title()\n",
        "\n",
        "# Aggregate soil data by province (get most common values)\n",
        "def get_mode_or_default(series, default='Medium'):\n",
        "    \"\"\"Get mode value or return default if empty.\"\"\"\n",
        "    mode_values = series.mode()\n",
        "    return mode_values[0] if len(mode_values) > 0 else default\n",
        "\n",
        "province_soil_agg = soil_test_df.groupby('province_normalized').agg({\n",
        "    'nitrogen': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'phosphorus': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'potassium': lambda x: get_mode_or_default(x, 'Medium'),\n",
        "    'ph_min': 'mean',\n",
        "    'ph_max': 'mean'\n",
        "}).reset_index()\n",
        "province_soil_agg.columns = ['province', 'nitrogen', 'phosphorus', 'potassium', 'ph_min', 'ph_max']\n",
        "\n",
        "print(f\"Aggregated soil data for {len(province_soil_agg)} provinces\")\n",
        "\n",
        "# Normalize province names in historical data for merging\n",
        "historical_perf_clean['Province_normalized'] = historical_perf_clean['Province'].str.strip().str.title()\n",
        "\n",
        "# Merge historical performance with soil data\n",
        "print(\"\\nMerging historical data with soil data...\")\n",
        "merged_data = historical_perf_clean.merge(\n",
        "    province_soil_agg,\n",
        "    left_on='Province_normalized',\n",
        "    right_on='province',\n",
        "    how='inner'  # Only keep records with soil data\n",
        ")\n",
        "\n",
        "print(f\"Total merged records: {len(merged_data)}\")\n",
        "print(f\"Records with soil data: {merged_data['nitrogen'].notna().sum()}\")\n",
        "print(f\"Unique crop-province combinations with soil data: {merged_data[['Crop', 'Province']].drop_duplicates().shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dynamic Suitability Score and Realistic Soil Types\n",
        "\n",
        "To improve our training data, we'll make two key changes:\n",
        "\n",
        "1.  **Dynamic Suitability Score**: Instead of a fixed maximum yield, we'll calculate the 95th percentile of each crop's historical yield. This makes the score more adaptive to the typical performance of each crop.\n",
        "2.  **Realistic Soil Types**: Instead of using \"Loam\" for all samples, we'll randomly select a suitable soil type for each crop from its list of acceptable soils."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the 95th percentile yield for each crop\n",
        "max_yield_per_crop = historical_perf_clean.groupby('Crop')['yield_per_ha'].quantile(0.95)\n",
        "\n",
        "# Create training dataset using the entire merged dataset\n",
        "training_data = []\n",
        "\n",
        "print(f\"Processing {len(merged_data)} records...\")\n",
        "\n",
        "for idx, row in merged_data.iterrows():\n",
        "    crop_name = row['Crop']\n",
        "    province = row['Province']\n",
        "    yield_per_ha = row['yield_per_ha']\n",
        "    \n",
        "    try:\n",
        "        crop_data = data_loader.get_crop_by_name(crop_name)\n",
        "        if crop_data is None:\n",
        "            continue\n",
        "        \n",
        "        climate = data_loader.get_climate_averages(province, None)\n",
        "        if not all([climate['temperature'], climate['rainfall'], climate['humidity']]):\n",
        "            continue\n",
        "        \n",
        "        # Use a realistic soil type\n",
        "        acceptable_soils = parse_soil_types(crop_data.get('Acceptable_Soil_Types', 'Loam'))\n",
        "        farmer_soil_type = random.choice(acceptable_soils) if acceptable_soils else 'Loam'\n",
        "\n",
        "        features = feature_extractor.extract_features(\n",
        "            crop_data=crop_data,\n",
        "            farmer_nitrogen=str(row['nitrogen']),\n",
        "            farmer_phosphorus=str(row['phosphorus']),\n",
        "            farmer_potassium=str(row['potassium']),\n",
        "            farmer_ph_min=float(row['ph_min']),\n",
        "            farmer_ph_max=float(row['ph_max']),\n",
        "            farmer_soil_type=farmer_soil_type,\n",
        "            avg_temperature=climate['temperature'],\n",
        "            avg_rainfall=climate['rainfall'],\n",
        "            avg_humidity=climate['humidity'],\n",
        "            historical_yield_data=data_loader.get_historical_yield(crop_name, province),\n",
        "            current_month=6\n",
        "        )\n",
        "        \n",
        "        # Dynamic suitability score\n",
        "        max_yield = max_yield_per_crop.get(crop_name, 20) # Default to 20 if crop not in series\n",
        "        suitability_score = min(100.0, max(0.0, (yield_per_ha / max_yield) * 80.0 + 20.0))\n",
        "        \n",
        "        training_row = features.copy()\n",
        "        training_row['suitability_score'] = suitability_score\n",
        "        training_row['crop_name'] = crop_name\n",
        "        training_row['province'] = province\n",
        "        training_row['category'] = crop_data.get('Category', 'Unknown')\n",
        "        training_row['actual_yield'] = yield_per_ha\n",
        "        \n",
        "        training_data.append(training_row)\n",
        "        \n",
        "    except Exception as e:\n",
        "        continue\n",
        "    \n",
        "    if len(training_data) % 5000 == 0:\n",
        "        print(f\"Processed {len(training_data)} records...\")\n",
        "\n",
        "print(f\"\\nTotal training records created: {len(training_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to DataFrame\n",
        "train_df = pd.DataFrame(training_data)\n",
        "print(\"Full dataset shape:\", train_df.shape)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_set, val_set = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: {train_set.shape}\")\n",
        "print(f\"Validation set shape: {val_set.shape}\")\n",
        "\n",
        "# Save the datasets\n",
        "output_dir = Path(\"../models\")\n",
        "train_set.to_csv(output_dir / \"training_dataset.csv\", index=False)\n",
        "val_set.to_csv(output_dir / \"validation_dataset.csv\", index=False)\n",
        "\n",
        "print(\"\\nTraining and validation datasets saved successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
